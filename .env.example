# OpenAI API Key for LLM
OPENAI_API_KEY=your-openai-api-key

# Anthropic API Key (only needed if using Anthropic provider)
ANTHROPIC_API_KEY=your-anthropic-api-key

# LangSmith Configuration for Observability
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_PROJECT=python-mcp-agent
LANGSMITH_TRACING=true

# GitHub MCP Server Configuration
GITHUB_MCP_URL=https://api.githubcopilot.com/mcp/
GITHUB_TOKEN=your-github-token
GITHUB_OWNER=your-github-username
# Optional: create repos under an org instead of the authenticated user
# GITHUB_ORGANIZATION=your-org

# Azure DevOps MCP Server Configuration (for SDLC pipeline ADO push)
AZURE_DEVOPS_ORGANIZATION=your-ado-organization
AZURE_DEVOPS_PROJECT=your-ado-project
# PAT used by @azure-devops/mcp when auth_type=envvar
ADO_MCP_AUTH_TOKEN=your-azure-devops-pat

# SDLC optional: Azure Test Plans
# If SDLC_CREATE_TESTPLAN=true (or enabled interactively), the runner will create a Test Plan.
# Iteration is required by Azure DevOps, e.g. "YourProject\\Iteration 1".
SDLC_CREATE_TESTPLAN=false
SDLC_TESTPLAN_NAME=
SDLC_TESTPLAN_ITERATION=
SDLC_TESTPLAN_DESCRIPTION=
SDLC_TESTPLAN_ID=369
SDLC_TESTSUITE_ID=370

# SDLC optional: Mermaid diagram rendering via local MCP server (npx mcp-mermaid)
SDLC_RENDER_MERMAID=false
SDLC_MERMAID_OUTPUT_DIR=docs/diagrams

# SDLC optional: GitHub push + PR
SDLC_PUSH_TO_GITHUB=false
SDLC_GITHUB_REPO_NAME=
SDLC_GITHUB_OWNER=
SDLC_CREATE_PR=false
SDLC_PR_BRANCH=feature/auto-gen

# SDLC optional: If you want to limit how many stories are sent to code generation.
# By default, all stories are included.
# SDLC_CODEGEN_MAX_STORIES=25

# SDLC Agent LLM selection (do not put real keys here; keys go in OPENAI_API_KEY/ANTHROPIC_API_KEY)
# Provider: openai | anthropic
SDLC_LLM_PROVIDER_DEFAULT=anthropic
# SDLC_LLM_PROVIDER_ARCHITECT=openai
# SDLC_LLM_PROVIDER_DEVELOPER=anthropic
# SDLC_LLM_PROVIDER_GITHUB_AGENT=openai

# Model names are passed directly to the chosen provider SDK
SDLC_MODEL_DEFAULT=claude-3-opus-latest
# SDLC_MODEL_ARCHITECT=o1-preview
# SDLC_MODEL_DEVELOPER=claude-3-5-sonnet-latest
# SDLC_MODEL_GITHUB_AGENT=gpt-4o-mini

# Optional per-agent temperature
# SDLC_TEMPERATURE_ARCHITECT=0.2
# SDLC_TEMPERATURE_GITHUB_AGENT=0
