# OpenAI API Key for LLM
OPENAI_API_KEY=your-openai-api-key

# Anthropic API Key (only needed if using Anthropic provider)
ANTHROPIC_API_KEY=your-anthropic-api-key

# LangSmith Configuration for Observability
LANGSMITH_API_KEY=your-langsmith-api-key
LANGSMITH_PROJECT=python-mcp-agent
LANGSMITH_TRACING=true

# GitHub MCP Server Configuration
GITHUB_MCP_URL=https://api.githubcopilot.com/mcp/
GITHUB_TOKEN=your-github-token

# Azure DevOps MCP Server Configuration (for SDLC pipeline ADO push)
AZURE_DEVOPS_ORGANIZATION=your-ado-organization
AZURE_DEVOPS_PROJECT=your-ado-project
# PAT used by @azure-devops/mcp when auth_type=envvar
ADO_MCP_AUTH_TOKEN=your-azure-devops-pat

# SDLC Agent LLM selection (do not put real keys here; keys go in OPENAI_API_KEY/ANTHROPIC_API_KEY)
# Provider: openai | anthropic
SDLC_LLM_PROVIDER_DEFAULT=openai
# SDLC_LLM_PROVIDER_ARCHITECT=openai
# SDLC_LLM_PROVIDER_DEVELOPER=anthropic
# SDLC_LLM_PROVIDER_GITHUB_AGENT=openai

# Model names are passed directly to the chosen provider SDK
SDLC_MODEL_DEFAULT=gpt-4-turbo
# SDLC_MODEL_ARCHITECT=o1-preview
# SDLC_MODEL_DEVELOPER=claude-3-5-sonnet-latest
# SDLC_MODEL_GITHUB_AGENT=gpt-4o-mini

# Optional per-agent temperature
# SDLC_TEMPERATURE_ARCHITECT=0.2
# SDLC_TEMPERATURE_GITHUB_AGENT=0
